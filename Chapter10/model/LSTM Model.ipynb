{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'data/data-full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious request logs in dataset: 49.90%\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv(csv_file, quotechar='|', header=None)\n",
    "df_count = df.groupby([1]).count()\n",
    "total_req = df_count[0][0] + df_count[0][1]\n",
    "num_malicious = df_count[0][1]\n",
    "\n",
    "print(\"Malicious request logs in dataset: {:0.2f}%\".format(float(num_malicious) / total_req * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_values = df.sample(frac=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "X = df_values[:,0]\n",
    "Y = df_values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': 1502738627781,\n",
       " 'method': 'get',\n",
       " 'query': {'query': \"Dishwashers' OR '1'='1' --\"},\n",
       " 'path': '/search',\n",
       " 'statusCode': 404,\n",
       " 'source': {'remoteAddress': '197.88.19.135',\n",
       "  'referer': 'http://localhost:8002/enter'},\n",
       " 'route': '/search',\n",
       " 'headers': {'host': 'localhost:8002',\n",
       "  'accept-language': 'en-us',\n",
       "  'accept-encoding': 'gzip, deflate',\n",
       "  'connection': 'keep-alive',\n",
       "  'accept': '*/*',\n",
       "  'referer': 'http://localhost:8002/enter',\n",
       "  'cache-control': 'no-cache',\n",
       "  'x-requested-with': 'XMLHttpRequest'},\n",
       " 'requestPayload': None,\n",
       " 'responsePayload': {'statusCode': 404,\n",
       "  'error': 'Not Found',\n",
       "  'message': 'Not Found'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(X):\n",
    "    req = json.loads(item, object_pairs_hook=OrderedDict)\n",
    "    del req['timestamp']\n",
    "    del req['headers']\n",
    "    del req['source']\n",
    "    del req['route']\n",
    "    del req['responsePayload']\n",
    "    X[index] = json.dumps(req, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(tokenizer.word_index)+1\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "max_log_length = 1024\n",
    "split = int(len(df_values) * .75)\n",
    "\n",
    "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)\n",
    "X_train, X_test = X_processed[0:split], X_processed[split:len(X_processed)]\n",
    "Y_train, Y_test = Y[0:split], Y[split:len(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 12, 12, 19], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xprilion/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/xprilion/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=max_log_length))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1024, 32)          2016      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 26,913\n",
      "Trainable params: 26,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xprilion/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 15059 samples, validate on 5020 samples\n",
      "Epoch 1/3\n",
      "15059/15059 [==============================] - 337s 22ms/step - loss: 0.6201 - acc: 0.6557 - val_loss: 0.3987 - val_acc: 0.8351\n",
      "Epoch 2/3\n",
      "15059/15059 [==============================] - 312s 21ms/step - loss: 0.4515 - acc: 0.8062 - val_loss: 0.2831 - val_acc: 0.9040\n",
      "Epoch 3/3\n",
      "15059/15059 [==============================] - 283s 19ms/step - loss: 0.3305 - acc: 0.8920 - val_loss: 0.1854 - val_acc: 0.9602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5deff61ef0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_split=0.25, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6694/6694 [==============================] - 24s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, Y_test, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 96.47%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy: {:0.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save_weights('weights.h5')\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
